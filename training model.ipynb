{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7efe140"
      },
      "source": [
        "# Step [1]: Prepare libraries and data"
      ],
      "id": "e7efe140"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e9b1951"
      },
      "source": [
        "## [1.1] Include important libraries"
      ],
      "id": "8e9b1951"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af6058ed"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ],
      "id": "af6058ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "229df102"
      },
      "source": [
        "## [1.2] Download data"
      ],
      "id": "229df102"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5504e7ee",
        "outputId": "0f3977c3-42b0-4115-9e17-cdfeb1a5cfd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-12 18:12:44--  https://drive.google.com/uc?export=download&id=1KepfzAhJ7dloG8XaWQf0ovQipDHYS8aI\n",
            "Resolving drive.google.com (drive.google.com)... 74.125.133.113, 74.125.133.101, 74.125.133.100, ...\n",
            "Connecting to drive.google.com (drive.google.com)|74.125.133.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rage0lkntg5tq85ut47ii97krhkri4u2/1639332750000/04260309330816471542/*/1KepfzAhJ7dloG8XaWQf0ovQipDHYS8aI?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-12-12 18:12:46--  https://doc-0o-00-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/rage0lkntg5tq85ut47ii97krhkri4u2/1639332750000/04260309330816471542/*/1KepfzAhJ7dloG8XaWQf0ovQipDHYS8aI?e=download\n",
            "Resolving doc-0o-00-docs.googleusercontent.com (doc-0o-00-docs.googleusercontent.com)... 64.233.167.132, 2a00:1450:400c:c0a::84\n",
            "Connecting to doc-0o-00-docs.googleusercontent.com (doc-0o-00-docs.googleusercontent.com)|64.233.167.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2962196 (2.8M) [application/zip]\n",
            "Saving to: ‚Äòfinal_data.zip‚Äô\n",
            "\n",
            "final_data.zip      100%[===================>]   2.82M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-12-12 18:12:46 (142 MB/s) - ‚Äòfinal_data.zip‚Äô saved [2962196/2962196]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget 'https://drive.google.com/uc?export=download&id=1KepfzAhJ7dloG8XaWQf0ovQipDHYS8aI' -O 'final_data.zip'"
      ],
      "id": "5504e7ee"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "530e1bac",
        "outputId": "8fe6ca9d-a482-4df5-a6af-6313499b2c7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  final_data.zip\n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n",
            "  inflating: valid.csv               \n"
          ]
        }
      ],
      "source": [
        "!unzip final_data.zip"
      ],
      "id": "530e1bac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3400638b"
      },
      "source": [
        "## [1.3] read data from csv file"
      ],
      "id": "3400638b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "d41a9612",
        "outputId": "2369ec4e-3f3d-4834-e62c-bc95cb65ee68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#ÿ™ÿ®ŸÜŸä_ŸÇÿ∑ÿ∑_ÿßŸÜŸÇÿßÿ∞ ŸÖŸÜ ÿßŸÑÿÆÿßÿµ ŸáÿßÿßÿßÿßŸÖ ŸÉŸäÿ™ŸÜ ÿ£ŸÜÿ´Ÿâ ÿπŸÖÿ±Ÿá...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>'#ÿÆÿ∞_ÿßŸÑÿÆÿ∑Ÿàÿ©_ÿÆÿ∞_ÿßŸÑŸÑŸÇÿßÿ≠ \\nÿßŸÑÿ≠ŸÖÿØÿßŸÑŸÑŸá ŸÖŸÜ ŸÇÿ®ŸÑ ŸàŸÖŸÜ ÿ®...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ŸÑŸà ÿßŸÑŸÑŸä ŸÖÿ´ŸÑŸÉ Ÿàÿ¥ÿ±ŸàÿßŸÉ ÿ∑ÿπŸÖŸà ŸÉÿßŸÜ ŸÇÿØ ÿ≠ÿ∞ŸÅŸÜÿß ÿßŸÑŸÉŸÖÿßŸÖÿßÿ™...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#ÿßŸÑÿµÿ≠ÿ©:‚Ä¢ŸÜÿ≠Ÿà 14.5 ŸÖŸÑŸäŸàŸÜ ÿ¥ÿÆÿµ ÿ™ŸÖ ÿ•ÿπÿ∑ÿßÿ§ŸáŸÖ ÿ¨ÿ±ÿπÿ© ŸÑŸÇÿß...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>‚Ä¢ ŸÅŸä ŸÖŸÜÿ∏Ÿàÿ± ÿßŸÑŸÇŸàÿ© ÿßŸÑÿ®ÿ¥ÿ±Ÿäÿ© ( ÿßŸÑÿ£ÿ≤ŸÖÿ© ÿ≥ÿ™ÿ∑ŸàŸÑ ŸÑÿ£ÿ¥Ÿáÿ± ...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ÿØŸàŸÑ ÿ±ŸÅÿπÿ™ ÿ¥ÿπÿßÿ± ŸÑŸÇÿßÿ≠ #ŸÉŸàÿ±ŸàŸÜÿß ŸÖÿ¨ÿßŸÜÿß ŸÑŸÉÿßŸÅÿ© ÿßŸÑŸÖŸàÿßÿ∑...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>@mayahaydarali ÿ∑Ÿäÿ® ŸÑŸäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ© ÿ≤Ÿä ŸÖÿßŸÉÿ™ÿ¥ŸÅÿ™ ŸÑŸÇÿß...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>üö®ÿßŸÑÿ≥ŸÑÿ∑ÿßÿ™ ÿßŸÑÿµÿ≠Ÿäÿ© ÿ™ÿπŸÑŸÜ ÿ™ÿ∑ÿπŸäŸÖ ÿ£ŸÉÿ´ÿ± ŸÖŸÜ ŸÜÿµŸÅ ŸÖŸÑŸäŸàŸÜ ÿ∑...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ÿ®Ÿàÿ™ŸäŸÜ Ÿäÿ≠ÿµŸÑ ŸÖÿ¨ÿØÿØŸãÿß ÿπŸÑŸâ ŸÑŸÇÿßÿ≠ ŸÖÿ∂ÿßÿØ ŸÑŸÅŸäÿ±Ÿàÿ≥ ŸÉŸàÿ±ŸàŸÜÿß ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ÿ™ÿ≥ÿπŸâ ÿ¥ÿ±ŸÉŸá ŸÖŸàÿØÿ±ŸÜÿß ÿßŸÑÿ£ŸÖÿ±ŸäŸÉŸäŸá ŸÑÿßÿ≥ÿ™ÿµÿØÿßÿ± ÿ™ÿ±ÿÆŸäÿµ ŸÖŸÜ Ÿá...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               tweet  label\n",
              "0  #ÿ™ÿ®ŸÜŸä_ŸÇÿ∑ÿ∑_ÿßŸÜŸÇÿßÿ∞ ŸÖŸÜ ÿßŸÑÿÆÿßÿµ ŸáÿßÿßÿßÿßŸÖ ŸÉŸäÿ™ŸÜ ÿ£ŸÜÿ´Ÿâ ÿπŸÖÿ±Ÿá...      2\n",
              "1  '#ÿÆÿ∞_ÿßŸÑÿÆÿ∑Ÿàÿ©_ÿÆÿ∞_ÿßŸÑŸÑŸÇÿßÿ≠ \\nÿßŸÑÿ≠ŸÖÿØÿßŸÑŸÑŸá ŸÖŸÜ ŸÇÿ®ŸÑ ŸàŸÖŸÜ ÿ®...      1\n",
              "2  ŸÑŸà ÿßŸÑŸÑŸä ŸÖÿ´ŸÑŸÉ Ÿàÿ¥ÿ±ŸàÿßŸÉ ÿ∑ÿπŸÖŸà ŸÉÿßŸÜ ŸÇÿØ ÿ≠ÿ∞ŸÅŸÜÿß ÿßŸÑŸÉŸÖÿßŸÖÿßÿ™...      1\n",
              "3  #ÿßŸÑÿµÿ≠ÿ©:‚Ä¢ŸÜÿ≠Ÿà 14.5 ŸÖŸÑŸäŸàŸÜ ÿ¥ÿÆÿµ ÿ™ŸÖ ÿ•ÿπÿ∑ÿßÿ§ŸáŸÖ ÿ¨ÿ±ÿπÿ© ŸÑŸÇÿß...      1\n",
              "4  ‚Ä¢ ŸÅŸä ŸÖŸÜÿ∏Ÿàÿ± ÿßŸÑŸÇŸàÿ© ÿßŸÑÿ®ÿ¥ÿ±Ÿäÿ© ( ÿßŸÑÿ£ÿ≤ŸÖÿ© ÿ≥ÿ™ÿ∑ŸàŸÑ ŸÑÿ£ÿ¥Ÿáÿ± ...      3\n",
              "5   ÿØŸàŸÑ ÿ±ŸÅÿπÿ™ ÿ¥ÿπÿßÿ± ŸÑŸÇÿßÿ≠ #ŸÉŸàÿ±ŸàŸÜÿß ŸÖÿ¨ÿßŸÜÿß ŸÑŸÉÿßŸÅÿ© ÿßŸÑŸÖŸàÿßÿ∑...      3\n",
              "6  @mayahaydarali ÿ∑Ÿäÿ® ŸÑŸäÿ© ÿßŸÑÿ≥ÿπŸàÿØŸäÿ© ÿ≤Ÿä ŸÖÿßŸÉÿ™ÿ¥ŸÅÿ™ ŸÑŸÇÿß...      3\n",
              "7  üö®ÿßŸÑÿ≥ŸÑÿ∑ÿßÿ™ ÿßŸÑÿµÿ≠Ÿäÿ© ÿ™ÿπŸÑŸÜ ÿ™ÿ∑ÿπŸäŸÖ ÿ£ŸÉÿ´ÿ± ŸÖŸÜ ŸÜÿµŸÅ ŸÖŸÑŸäŸàŸÜ ÿ∑...      3\n",
              "8  ÿ®Ÿàÿ™ŸäŸÜ Ÿäÿ≠ÿµŸÑ ŸÖÿ¨ÿØÿØŸãÿß ÿπŸÑŸâ ŸÑŸÇÿßÿ≠ ŸÖÿ∂ÿßÿØ ŸÑŸÅŸäÿ±Ÿàÿ≥ ŸÉŸàÿ±ŸàŸÜÿß ...      1\n",
              "9  ÿ™ÿ≥ÿπŸâ ÿ¥ÿ±ŸÉŸá ŸÖŸàÿØÿ±ŸÜÿß ÿßŸÑÿ£ŸÖÿ±ŸäŸÉŸäŸá ŸÑÿßÿ≥ÿ™ÿµÿØÿßÿ± ÿ™ÿ±ÿÆŸäÿµ ŸÖŸÜ Ÿá...      1"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"test.csv\")\n",
        "validation = pd.read_csv(\"valid.csv\")\n",
        "train.head(10)"
      ],
      "id": "d41a9612"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ec48c7b"
      },
      "source": [
        "## [1.4] Prapere The Comparison Dictionary"
      ],
      "id": "4ec48c7b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dfcdcdfc"
      },
      "outputs": [],
      "source": [
        "model_comparison_table = {}"
      ],
      "id": "dfcdcdfc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0428b0f2"
      },
      "outputs": [],
      "source": [
        "model_comparison_table['model_name'] = []\n",
        "model_comparison_table['preprocessing_methods'] = []\n",
        "model_comparison_table['accuracy'] = []"
      ],
      "id": "0428b0f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2f22713d"
      },
      "source": [
        "# Step [2]: Build Baseline"
      ],
      "id": "2f22713d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03ef90d1"
      },
      "source": [
        "## [2.1] Extract Bag of Words Features"
      ],
      "id": "03ef90d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mmz-zXe8j0LT"
      },
      "source": [
        "Getting X_Train and Y_Train"
      ],
      "id": "Mmz-zXe8j0LT"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1b8c64b",
        "outputId": "c52f8cfa-22b6-4705-acb3-ab2969f1230e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8117\n"
          ]
        }
      ],
      "source": [
        "X_Train = []\n",
        "Y_Train = []\n",
        "for i in range(len(train)):\n",
        "  if train.values[i][1] == 0 or train.values[i][1] == 1:\n",
        "    X_Train.append(train.values[i][0])\n",
        "    Y_Train.append(train.values[i][1])\n",
        "print(len(X_Train))"
      ],
      "id": "c1b8c64b"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0y1T8_Mqj6QK"
      },
      "source": [
        "Getting X_Test and Y_Test"
      ],
      "id": "0y1T8_Mqj6QK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K39Vl-mEklPy",
        "outputId": "9f7fffd0-6ae5-44ab-87b4-82a30796812f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2717\n"
          ]
        }
      ],
      "source": [
        "X_Test = []\n",
        "Y_Test = []\n",
        "for i in range(len(test)):\n",
        "  if test.values[i][1] == 0 or test.values[i][1] == 1:\n",
        "    X_Test.append(test.values[i][0])\n",
        "    Y_Test.append(test.values[i][1])\n",
        "print(len(X_Test))"
      ],
      "id": "K39Vl-mEklPy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YD1HF3Gxk1P7"
      },
      "source": [
        "Transform X_Train and X_Test to Bag of words representation"
      ],
      "id": "YD1HF3Gxk1P7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urdA60kwiKCN",
        "outputId": "a6195166-cdc2-4a49-9a1b-a1af3a571a90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8117, 42641)\n",
            "(2717, 42641)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "def BOW(X_data):\n",
        "    count_vectorizer = CountVectorizer()\n",
        "    \n",
        "    X_Bow = count_vectorizer.fit_transform(X_data)\n",
        "    \n",
        "    return X_Bow,count_vectorizer\n",
        "\n",
        "X_Train_BOW , CV = BOW(X_Train)\n",
        "X_Test_BOW = CV.transform(X_Test)\n",
        "print(X_Train_BOW.toarray().shape)\n",
        "print(X_Test_BOW.toarray().shape)"
      ],
      "id": "urdA60kwiKCN"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24164796"
      },
      "source": [
        "## [2.2] Train model"
      ],
      "id": "24164796"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04e373c4",
        "outputId": "7cacf271-d558-4929-f8b1-3c0c766c7bd3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "clf = LogisticRegression(random_state=40)\n",
        "clf.fit(X_Train_BOW, Y_Train)\n",
        "\n",
        "Y_Predicted = clf.predict(X_Test_BOW)"
      ],
      "id": "04e373c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a286e05a"
      },
      "source": [
        "## [2.3] Evaluation"
      ],
      "id": "a286e05a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e011a54",
        "outputId": "f551f4e7-183b-4a30-85da-1f2a25f967f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7765918292234082"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "acc = accuracy_score(Y_Test, Y_Predicted)\n",
        "acc"
      ],
      "id": "7e011a54"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "42b0c136"
      },
      "outputs": [],
      "source": [
        "model_comparison_table['model_name'].append(\"logistic regression with bag of words\")\n",
        "model_comparison_table['preprocessing_methods'].append(\"none\")\n",
        "model_comparison_table['accuracy'].append(0.7765918292234082)"
      ],
      "id": "42b0c136"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9e52feb"
      },
      "source": [
        "# Step [3]: Build model with preprocessing methods"
      ],
      "id": "f9e52feb"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_9Y-8uDyVIa"
      },
      "source": [
        "## [3.1] Get My Previous Work"
      ],
      "id": "i_9Y-8uDyVIa"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgZG8gewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwoKICAgICAgbGV0IHBlcmNlbnREb25lID0gZmlsZURhdGEuYnl0ZUxlbmd0aCA9PT0gMCA/CiAgICAgICAgICAxMDAgOgogICAgICAgICAgTWF0aC5yb3VuZCgocG9zaXRpb24gLyBmaWxlRGF0YS5ieXRlTGVuZ3RoKSAqIDEwMCk7CiAgICAgIHBlcmNlbnQudGV4dENvbnRlbnQgPSBgJHtwZXJjZW50RG9uZX0lIGRvbmVgOwoKICAgIH0gd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCk7CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "d605c22a",
        "outputId": "78df874c-77e4-4466-af6b-22e2efe7af84"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-66d17305-19fd-40b3-afd2-bf699b9ef36d\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-66d17305-19fd-40b3-afd2-bf699b9ef36d\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving preprocessing.py to preprocessing.py\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6211"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "from google.colab import files\n",
        "src = list(files.upload().values())[0]\n",
        "open('preprocessing.py','wb').write(src)"
      ],
      "id": "d605c22a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FoWO4cBIEbr3"
      },
      "source": [
        "## [3.2] BOW + Logistic Regression + One Preprocessing Method"
      ],
      "id": "FoWO4cBIEbr3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0ARyI_SFi9U",
        "outputId": "185345a3-9f62-499b-9221-61fb67fde176"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.7784320942215679,\n",
              " 0.7821126242178874,\n",
              " 0.7732793522267206,\n",
              " 0.7791682002208318,\n",
              " 0.777695988222304,\n",
              " 0.7729112992270887,\n",
              " 0.7784320942215679,\n",
              " 0.777695988222304,\n",
              " 0.7806404122193595,\n",
              " 0.7732793522267206,\n",
              " 0.7729112992270887]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import preprocessing\n",
        "flags = [0,0,0,0,0,0,0,0,0,0,0]\n",
        "acc = []\n",
        "for j in range(len(flags)):\n",
        "  flags[j] = 1\n",
        "\n",
        "  X_Train = []\n",
        "  Y_Train = []\n",
        "  for i in range(len(train)):\n",
        "    if train.values[i][1] == 0 or train.values[i][1] == 1:\n",
        "      cleaned_tweet = preprocessing.preprocess(train.values[i][0],flags)\n",
        "      X_Train.append(cleaned_tweet)\n",
        "      Y_Train.append(train.values[i][1])\n",
        "  \n",
        "  X_Test = []\n",
        "  Y_Test = []\n",
        "  for i in range(len(test)):\n",
        "    if test.values[i][1] == 0 or test.values[i][1] == 1:\n",
        "      cleaned_tweet = preprocessing.preprocess(test.values[i][0],flags)\n",
        "      X_Test.append(cleaned_tweet)\n",
        "      Y_Test.append(test.values[i][1])\n",
        "  \n",
        "  X_Train_BOW , CV = BOW(X_Train)\n",
        "  X_Test_BOW = CV.transform(X_Test)\n",
        "\n",
        "  clf = LogisticRegression(random_state=40)\n",
        "  clf.fit(X_Train_BOW, Y_Train)\n",
        "  Y_Predicted = clf.predict(X_Test_BOW)\n",
        "  acc.append(accuracy_score(Y_Test, Y_Predicted))\n",
        "\n",
        "  flags[j] = 0\n",
        "acc"
      ],
      "id": "F0ARyI_SFi9U"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d4969b90"
      },
      "source": [
        "## [3.3] Updating comparison table"
      ],
      "id": "d4969b90"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRwlR4Qusa6v"
      },
      "outputs": [],
      "source": [
        "pre = ['unified different written words','remove urls','remove mentions','remove repetitive chars','remove numbers','remove punctuation','remove emojis','remove stopwords','stemming','unified chars','remove not arabic words']\n",
        "\n",
        "for i in range(len(pre)):\n",
        "  model_comparison_table['model_name'].append(\"logistic regression with bag of words\")\n",
        "  model_comparison_table['preprocessing_methods'].append(pre[i])\n",
        "  model_comparison_table['accuracy'].append(acc[i])"
      ],
      "id": "ZRwlR4Qusa6v"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px_bGoC7UQlm"
      },
      "source": [
        "# Step [4]: tfidf + Logistic Regression + best preprocessing methods"
      ],
      "id": "Px_bGoC7UQlm"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pygyGiWGT8tt"
      },
      "source": [
        "## [4.1] get best preprocessing methods"
      ],
      "id": "pygyGiWGT8tt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00d03133"
      },
      "outputs": [],
      "source": [
        "BaseLineAcc = 0.7765918292234082\n",
        "good = []\n",
        "for i in range(11):\n",
        "  if acc[i] > BaseLineAcc :\n",
        "    good.append(i)\n",
        "flags = [0,0,0,0,0,0,0,0,0,0,0]\n",
        "for i in range(len(good)):\n",
        "  flags[good[i]]=1"
      ],
      "id": "00d03133"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXJECYCMUO4N"
      },
      "source": [
        "## [4.2] Data Preprocessing"
      ],
      "id": "eXJECYCMUO4N"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86e42fa2",
        "outputId": "fdba7361-97ba-4bd7-8cc3-cd95083a9607"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(8117, 2837)\n",
            "(2717, 2837)\n"
          ]
        }
      ],
      "source": [
        "import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "X_Train = []\n",
        "Y_Train = []\n",
        "for i in range(len(train)):\n",
        "  if train.values[i][1] == 0 or train.values[i][1] == 1:\n",
        "    cleaned_tweet = preprocessing.preprocess(train.values[i][0],flags)\n",
        "    X_Train.append(cleaned_tweet)\n",
        "    Y_Train.append(train.values[i][1])\n",
        "\n",
        "X_Test = []\n",
        "Y_Test = []\n",
        "for i in range(len(test)):\n",
        "    if test.values[i][1] == 0 or test.values[i][1] == 1:\n",
        "      cleaned_tweet = preprocessing.preprocess(test.values[i][0],flags)\n",
        "      X_Test.append(cleaned_tweet)\n",
        "      Y_Test.append(test.values[i][1])"
      ],
      "id": "86e42fa2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b9c515ad"
      },
      "source": [
        "## [4.3] Train and evaluate with parameter tuning"
      ],
      "id": "b9c515ad"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is5xKhSBayHD",
        "outputId": "dd51fa9b-4554-4ee6-9cb9-12c434e814dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7740154582259845"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def tfidf(data,min,max,ngram_max):\n",
        "    tfidf_vectorizer = TfidfVectorizer(min_df=min, max_df=max, ngram_range=(1, ngram_max))\n",
        "\n",
        "    train = tfidf_vectorizer.fit_transform(data)\n",
        "\n",
        "    return train, tfidf_vectorizer\n",
        "\n",
        "maxAcc = 0\n",
        "best_min = 0\n",
        "best_max = 0\n",
        "best_ngram_max = 0\n",
        "for i in range(2,15):\n",
        "  for j in range(4,9):\n",
        "    for k in range(2,5):\n",
        "      X_Train_tfidf, vec = tfidf(X_Train,i,j/10,k)\n",
        "      X_Test_Tfidf = vec.transform(X_Test)\n",
        "      clf = LogisticRegression(random_state=40)\n",
        "      clf.fit(X_Train_tfidf, Y_Train)\n",
        "      Y_Predicted = clf.predict(X_Test_Tfidf)\n",
        "      acc = accuracy_score(Y_Test, Y_Predicted)\n",
        "      if acc > maxAcc:\n",
        "        best_min = i\n",
        "        best_max = j/10\n",
        "        best_ngram_max = k\n",
        "        maxAcc=acc\n",
        "maxAcc"
      ],
      "id": "is5xKhSBayHD"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nM9RVw5IgI3h"
      },
      "source": [
        "## [4.4] Updating comparison table"
      ],
      "id": "nM9RVw5IgI3h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7TN0qGrgUx0"
      },
      "outputs": [],
      "source": [
        "p=\"\"\n",
        "for i in range(len(good)):\n",
        "  p += pre[good[i]] + \" + \"\n",
        "model_comparison_table['model_name'].append(\"tfidf + Logistic Regression\")\n",
        "model_comparison_table['preprocessing_methods'].append(p)\n",
        "model_comparison_table['accuracy'].append(0.7740154582259845)"
      ],
      "id": "S7TN0qGrgUx0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhkQlGAHicJc"
      },
      "source": [
        "## [4.5] Trying Another Machine Leaning Algorithm"
      ],
      "id": "lhkQlGAHicJc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fsrMn29PiiaY",
        "outputId": "550b082d-d06a-469b-89ca-c3a552e035d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.7880014722119986"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "\n",
        "X_Train_tfidf, vec = tfidf(X_Train,best_min,best_max,best_ngram_max)\n",
        "X_Test_Tfidf = vec.transform(X_Test)\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_Train_tfidf, Y_Train)\n",
        "Y_Predicted = clf.predict(X_Test_Tfidf)\n",
        "acc = accuracy_score(Y_Test, Y_Predicted)\n",
        "acc"
      ],
      "id": "fsrMn29PiiaY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr9EZWV6ydO1"
      },
      "outputs": [],
      "source": [
        "model_comparison_table['model_name'].append(\"SVM with tfidf\")\n",
        "model_comparison_table['preprocessing_methods'].append(p)\n",
        "model_comparison_table['accuracy'].append(0.7880014722119986)"
      ],
      "id": "Jr9EZWV6ydO1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc3kud1bdjH6"
      },
      "source": [
        "# STEP[5] : Deep Learning Model"
      ],
      "id": "uc3kud1bdjH6"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nVUh92xUd19h"
      },
      "source": [
        "## [5.1] Data Preprocessing "
      ],
      "id": "nVUh92xUd19h"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCvTKWxndrNh",
        "outputId": "545f3413-534e-4903-957e-7a767bbd9182"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.6.1)\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "(8117, 9836)\n",
            "(2717, 9836)\n",
            "(2688, 9836)\n"
          ]
        }
      ],
      "source": [
        "import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "flags = [1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
        "X_Train = []\n",
        "Y_Train = []\n",
        "for i in range(len(train)):\n",
        "  if train.values[i][1] == 0 or train.values[i][1] == 1:\n",
        "    cleaned_tweet = preprocessing.preprocess(train.values[i][0],flags)\n",
        "    X_Train.append(cleaned_tweet)\n",
        "    Y_Train.append(train.values[i][1])\n",
        "\n",
        "X_Test = []\n",
        "Y_Test = []\n",
        "for i in range(len(test)):\n",
        "    if test.values[i][1] == 0 or test.values[i][1] == 1:\n",
        "      cleaned_tweet = preprocessing.preprocess(test.values[i][0],flags)\n",
        "      X_Test.append(cleaned_tweet)\n",
        "      Y_Test.append(test.values[i][1])\n",
        "\n",
        "X_Valid = []\n",
        "Y_Valid = []\n",
        "for i in range(len(validation)):\n",
        "    if validation.values[i][1] == 0 or validation.values[i][1] == 1:\n",
        "      cleaned_tweet = preprocessing.preprocess(validation.values[i][0],flags)\n",
        "      X_Valid.append(cleaned_tweet)\n",
        "      Y_Valid.append(validation.values[i][1])\n",
        "\n",
        "def tfidf(data):\n",
        "    tfidf_vectorizer = TfidfVectorizer(min_df=4, max_df=0.6, ngram_range=(1, 3))\n",
        "\n",
        "    train = tfidf_vectorizer.fit_transform(data)\n",
        "\n",
        "    return train, tfidf_vectorizer\n",
        "\n",
        "X_Train_tfidf, vec = tfidf(X_Train)\n",
        "X_Test_Tfidf = vec.transform(X_Test)\n",
        "X_Valid_tfidf = vec.transform(X_Valid)\n",
        "print(X_Train_tfidf.toarray().shape)\n",
        "print(X_Test_Tfidf.toarray().shape)\n",
        "print(X_Valid_tfidf.toarray().shape)"
      ],
      "id": "hCvTKWxndrNh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3DECrnThV96"
      },
      "source": [
        "## [5.2] Train Deep Learning Model "
      ],
      "id": "I3DECrnThV96"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TY7m0lXiHYR",
        "outputId": "1d94a5b2-9caf-401d-9bf6-3f5c4998355e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 1)                 9837      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1)                 2         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,841\n",
            "Trainable params: 9,841\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras.models import Sequential\n",
        "model = Sequential()\n",
        "model.add(layers.Dense(1, input_dim=X_Train_tfidf.toarray().shape[1], activation='sigmoid'))\n",
        "model.add(layers.Dense(1, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', \n",
        "               optimizer='adam', \n",
        "               metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "id": "1TY7m0lXiHYR"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cNXJvowlEha"
      },
      "outputs": [],
      "source": [
        "es = keras.callbacks.EarlyStopping()\n",
        "history = model.fit(X_Train_tfidf.toarray().tolist(), Y_Train,\n",
        "                     epochs=100,\n",
        "                     verbose=False,\n",
        "                     validation_data=(X_Valid_tfidf.toarray().tolist(), Y_Valid),\n",
        "                     batch_size=10,\n",
        "                    callbacks=[es])"
      ],
      "id": "8cNXJvowlEha"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mz0gqJqprs-5",
        "outputId": "3ae680ef-acfe-4634-f98f-ce11a7690759"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Accuracy:  0.6571\n",
            "Testing Accuracy:  0.6665\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(X_Train_tfidf.toarray().tolist(), Y_Train, verbose=False)\n",
        "print(\"Training Accuracy:  {:.4f}\".format(accuracy))\n",
        "loss, accuracy = model.evaluate(X_Test_Tfidf.toarray().tolist(), Y_Test, verbose=False)\n",
        "print(\"Testing Accuracy:  {:.4f}\".format(accuracy))"
      ],
      "id": "Mz0gqJqprs-5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E_MiocVKueYu"
      },
      "outputs": [],
      "source": [
        "model_comparison_table['model_name'].append(\"Deep NN with Dense Layers (overfitted model)\")\n",
        "model_comparison_table['preprocessing_methods'].append(p)\n",
        "model_comparison_table['accuracy'].append(0.7391)\n",
        "\n",
        "model_comparison_table['model_name'].append(\"Deep NN with Dense Layers\")\n",
        "model_comparison_table['preprocessing_methods'].append(p)\n",
        "model_comparison_table['accuracy'].append(0.6665)"
      ],
      "id": "E_MiocVKueYu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8noExnisygW8"
      },
      "source": [
        "# Step[6] : Training Best Model on all classes"
      ],
      "id": "8noExnisygW8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3RiZkOmOVv6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d240a08e-0e79-4ad8-998a-da7d75e91690"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5953192808431494"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "from sklearn import svm\n",
        "import preprocessing\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "flags = [1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0]\n",
        "X_Train = []\n",
        "Y_Train = []\n",
        "for i in range(len(train)):\n",
        "  if type(train.values[i][0]) is str:\n",
        "    cleaned_tweet = preprocessing.preprocess(train.values[i][0],flags)\n",
        "    X_Train.append(cleaned_tweet)\n",
        "    Y_Train.append(train.values[i][1])\n",
        "\n",
        "X_Test = []\n",
        "Y_Test = []\n",
        "for i in range(len(test)):\n",
        "  if type(test.values[i][0]) is str:\n",
        "      cleaned_tweet = preprocessing.preprocess(test.values[i][0],flags)\n",
        "      X_Test.append(cleaned_tweet)\n",
        "      Y_Test.append(test.values[i][1])\n",
        "\n",
        "\n",
        "def tfidf(data):\n",
        "    tfidf_vectorizer = TfidfVectorizer(min_df=4, max_df=0.6, ngram_range=(1, 3))\n",
        "\n",
        "    train = tfidf_vectorizer.fit_transform(data)\n",
        "\n",
        "    return train, tfidf_vectorizer\n",
        "\n",
        "\n",
        "X_Train_tfidf, vec = tfidf(X_Train)\n",
        "X_Test_Tfidf = vec.transform(X_Test)\n",
        "clf = svm.SVC()\n",
        "clf.fit(X_Train_tfidf, Y_Train)\n",
        "Y_Predicted = clf.predict(X_Test_Tfidf)\n",
        "acc = accuracy_score(Y_Test, Y_Predicted)\n",
        "acc"
      ],
      "id": "f3RiZkOmOVv6"
    },
    {
      "cell_type": "code",
      "source": [
        "model_comparison_table['model_name'].append(\"ALL CLASSES SVM with tfidf\")\n",
        "model_comparison_table['preprocessing_methods'].append(p)\n",
        "model_comparison_table['accuracy'].append(acc)"
      ],
      "metadata": {
        "id": "WgRfPqjf8Ty7"
      },
      "id": "WgRfPqjf8Ty7",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 582
        },
        "id": "1747f25c",
        "outputId": "1f449dc6-97db-410e-95d6-c99064f48a9a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>preprocessing_methods</th>\n",
              "      <th>accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>none</td>\n",
              "      <td>0.776592</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>unified different written words</td>\n",
              "      <td>0.778432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>remove urls</td>\n",
              "      <td>0.782113</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>remove mentions</td>\n",
              "      <td>0.773279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>remove repetitive chars</td>\n",
              "      <td>0.779168</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>remove numbers</td>\n",
              "      <td>0.777696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>remove punctuation</td>\n",
              "      <td>0.772911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>remove emojis</td>\n",
              "      <td>0.778432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>remove stopwords</td>\n",
              "      <td>0.777696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>stemming</td>\n",
              "      <td>0.780640</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>unified chars</td>\n",
              "      <td>0.773279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>logistic regression with bag of words</td>\n",
              "      <td>remove not arabic words</td>\n",
              "      <td>0.772911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tfidf + Logistic Regression</td>\n",
              "      <td>unified different written words + remove urls ...</td>\n",
              "      <td>0.774015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SVM with tfidf</td>\n",
              "      <td>unified different written words + remove urls ...</td>\n",
              "      <td>0.788001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Deep NN with Dense Layers (overfitted model)</td>\n",
              "      <td>unified different written words + remove urls ...</td>\n",
              "      <td>0.739100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Deep NN with Dense Layers</td>\n",
              "      <td>unified different written words + remove urls ...</td>\n",
              "      <td>0.666500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>ALL CLASSES SVM with tfidf</td>\n",
              "      <td>unified different written words + remove urls ...</td>\n",
              "      <td>0.595319</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                      model_name  ...  accuracy\n",
              "0          logistic regression with bag of words  ...  0.776592\n",
              "1          logistic regression with bag of words  ...  0.778432\n",
              "2          logistic regression with bag of words  ...  0.782113\n",
              "3          logistic regression with bag of words  ...  0.773279\n",
              "4          logistic regression with bag of words  ...  0.779168\n",
              "5          logistic regression with bag of words  ...  0.777696\n",
              "6          logistic regression with bag of words  ...  0.772911\n",
              "7          logistic regression with bag of words  ...  0.778432\n",
              "8          logistic regression with bag of words  ...  0.777696\n",
              "9          logistic regression with bag of words  ...  0.780640\n",
              "10         logistic regression with bag of words  ...  0.773279\n",
              "11         logistic regression with bag of words  ...  0.772911\n",
              "12                   tfidf + Logistic Regression  ...  0.774015\n",
              "13                                SVM with tfidf  ...  0.788001\n",
              "14  Deep NN with Dense Layers (overfitted model)  ...  0.739100\n",
              "15                     Deep NN with Dense Layers  ...  0.666500\n",
              "16                    ALL CLASSES SVM with tfidf  ...  0.595319\n",
              "\n",
              "[17 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df = pd.DataFrame(model_comparison_table)\n",
        "df"
      ],
      "id": "1747f25c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "382f9a49"
      },
      "outputs": [],
      "source": [
        "df.to_csv(\"odayTayeb.csv\", index=False)"
      ],
      "id": "382f9a49"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}